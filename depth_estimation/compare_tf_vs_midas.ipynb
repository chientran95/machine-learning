{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92eba177-42f0-460d-8f87-5310e72b5365",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from metrics import Metric"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24719d08-d947-499d-8950-e346371523fb",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "Result of Midas model is lower than trained tf model because some groundtruth depthmap has reverse near-far value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96f8220e-c97f-49b1-8b23-7cbc31b561cb",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67045675-ab3a-4fd2-9971-b1b4b387113a",
   "metadata": {},
   "outputs": [],
   "source": [
    "e1_res = pd.read_csv('metric_tfmodel.csv')\n",
    "e2_res = pd.read_csv('metric_midas.csv')\n",
    "e1_res.shape, e2_res.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12d0cf7c-b243-4865-aab9-f9fb088a385e",
   "metadata": {},
   "outputs": [],
   "source": [
    "e1_res.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28775afd-e9cb-4daf-abc4-bd231c43ceac",
   "metadata": {},
   "outputs": [],
   "source": [
    "e2_res.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90275f97-104f-410c-b7f7-758770ba5415",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_compare = pd.merge(e1_res, e2_res, on='img_path', how='inner', suffixes=('_e1', '_e2'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1aa1b90-9c16-466a-9feb-872ce6270a0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_metric = 'mean_absrel'\n",
    "res_compare['diff_{}'.format(check_metric)] = res_compare['{}_e1'.format(check_metric)] - res_compare['{}_e2'.format(check_metric)]\n",
    "res_compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e69d79fa-2351-4230-9c42-dd1413d46dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_compare['diff_{}'.format(check_metric)].max(), res_compare['diff_{}'.format(check_metric)].min()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82e5e441-fab4-44e8-99d8-c056c89118a5",
   "metadata": {},
   "source": [
    "### Load sample data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8200253-f60f-4abb-bfe5-422df22596ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_compare.nsmallest(5, 'diff_mean_absrel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cd4ef72-1041-4e9c-992a-82cf4767eaa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "choice = 19\n",
    "print(res_compare.iloc[choice])\n",
    "sample = res_compare.iloc[choice].img_path\n",
    "sample"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f977706-04c3-4c89-a30d-722e101af3b3",
   "metadata": {},
   "source": [
    "### Load both models to check result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "add74968-e0b2-42eb-885c-b4d8cb0a9d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from tensorflow import keras\n",
    "from e1_data_generator import DataGenerator\n",
    "from utils import tf_visualize_depth_map, process_depth_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e9186a0-972f-43da-bbb5-d47bd0bc4764",
   "metadata": {},
   "outputs": [],
   "source": [
    "HEIGHT = 256\n",
    "WIDTH = 256\n",
    "BATCH_SIZE = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50e04dbb-9a65-4df4-bda8-f779d1beb1f8",
   "metadata": {},
   "source": [
    "##### Load tf model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43c11342-92d6-4fff-b7d9-b5d4ae63567a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_model = keras.models.load_model('checkpoint/model_1653373548.903842/')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1bbe009-5b69-474d-a4a9-f87604efea9c",
   "metadata": {},
   "source": [
    "##### Load torch Midas model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9812cc6e-0671-4599-a3f7-a1e0ac336d2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_type = \"DPT_Hybrid\"\n",
    "\n",
    "midas = torch.hub.load(\"intel-isl/MiDaS\", model_type)\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "midas.to(device)\n",
    "midas.eval()\n",
    "\n",
    "midas_transforms = torch.hub.load(\"intel-isl/MiDaS\", \"transforms\")\n",
    "transform = midas_transforms.dpt_transform"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60005d91-bd12-414e-ac03-a12ec74df93d",
   "metadata": {},
   "source": [
    "##### tf pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dafc1ad3-c08d-4979-95f0-02c7f646b213",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df = pd.DataFrame({'image': [sample], 'depth':[sample[:-4] + '_depth.npy'], 'mask': [sample[:-4] + '_depth_mask.npy']})\n",
    "sample_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "217b87b1-5d9d-4e77-ac4e-0e04b1f25f48",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = DataGenerator(\n",
    "    data=sample_df.reset_index(drop=\"true\"), batch_size=BATCH_SIZE, dim=(HEIGHT, WIDTH), shuffle=False, is_test=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5309a15-01f5-49f2-93a3-b32dd146646d",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path, inp, target = test_loader[0]\n",
    "tf_pred = tf_model.predict(inp)\n",
    "tf_pred = tf_pred[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "103595e4-5f93-4656-89d2-eb1bfbd0428e",
   "metadata": {},
   "source": [
    "##### torch midas pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4c8484c-a7d4-4faa-abff-a8cf0ba0db0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def general_normalize(data, origin_range, target_range):\n",
    "    ori_min, ori_max = origin_range\n",
    "    tar_min, tar_max = target_range\n",
    "    return tar_min + (data - ori_min) * ((tar_max - tar_min) / (ori_max - ori_min))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ff4011d-5e7b-4f7e-a816-a6ea303e9097",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    image_ = cv2.imread(sample)\n",
    "    image_ = cv2.cvtColor(image_, cv2.COLOR_BGR2RGB)\n",
    "    input_image = transform(image_).to(device)\n",
    "    h, w = input_image.shape[-2:]\n",
    "\n",
    "#     depth_map = process_depth_map(sample[:-4] + '_depth.npy', sample[:-4] + '_depth_mask.npy', (w,h))\n",
    "\n",
    "    pred = midas(input_image)\n",
    "    pred_np = pred.permute(1, 2, 0).numpy()\n",
    "    norm_pred = general_normalize(pred_np, (pred_np.min(), pred_np.max()), (target.min(), target.max()))\n",
    "norm_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35e58de1-a15c-498c-b254-f278704a838d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 4, figsize=(18, 18))\n",
    "cmap = plt.cm.jet\n",
    "cmap.set_bad(color=\"black\")\n",
    "\n",
    "ax[0].imshow(image_)\n",
    "ax[0].title.set_text('image')\n",
    "ax[1].imshow(target[0], cmap=cmap)\n",
    "ax[1].title.set_text('groundtruth')\n",
    "ax[2].imshow(tf_pred, cmap=cmap)\n",
    "ax[2].title.set_text('tf pred')\n",
    "ax[3].imshow(norm_pred, cmap=cmap)\n",
    "ax[3].title.set_text('midas pred')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accdd961-5dc1-4e4b-9699-7a29b8c67cf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_pred_reshaped = np.expand_dims(cv2.resize(norm_pred, (256, 256)), -1)\n",
    "fixed_norm_pred = -norm_pred_reshaped + norm_pred_reshaped.min() + norm_pred_reshaped.max()\n",
    "plt.imshow(fixed_norm_pred, cmap=cmap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d34b5f62-e8a7-4179-9046-cb69b5e45f99",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = Metric(target[0], fixed_norm_pred)\n",
    "print(metric.mean_absrel_err())\n",
    "print(metric.mean_sqrel_err())\n",
    "print(metric.rms_err())\n",
    "print(metric.rms_log_err())\n",
    "print(metric.percentage_of_pixel_acc()['delta1'])\n",
    "print(metric.percentage_of_pixel_acc()['delta2'])\n",
    "print(metric.percentage_of_pixel_acc()['delta3'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0af77c0b-fa06-4b45-ac5e-ae4b0d763867",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_compare.iloc[choice][['mean_absrel_e2', 'mean_sqrel_e2', 'rms_e2', 'rms_log_e2', 'delta1_e2', 'delta2_e2', 'delta3_e2']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e022b0f-fcd4-4eb2-96f7-e0c93b12c3f3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
